---
title: "mfinn13_originalHomeworkCode_04"
output: html_document
date: "2025-03-25"
---


## Problem 1: Z Test Function
Write a simple R function, Z.prop.test(), that can perform one- or two-sample Z-tests for proportion data, using the following guidelines:
Your function should take the following arguments: p1 and n1 (no default) representing the estimated proportion and sample size (i.e., based on your sample data); p2 and n2 (both defaulting to NULL) that contain a second sample‚Äôs proportion and sample size data in the event of a two-sample test; p0 (no default) as the expected value for the population proportion; and alternative (default ‚Äútwo.sided‚Äù) and conf.level (default 0.95), to be used in the same way as in the function t.test().

When conducting a two-sample test, it should be p1 that is tested as being smaller or larger than p2 when alternative= ‚Äúless‚Äù or alternative= ‚Äúgreater‚Äù, the same as in the use of x and y in the function t.test().

The function should perform a one-sample Z-test using p1, n1, and p0 if either p2 or n2 (or both) is NULL.

The function should contain a check for the rules of thumb we have talked about (ùëõ‚àóùëù>5
and ùëõ‚àó(1‚àíùëù)>5) to ensure the validity of assuming the normal distribution in both the one- and two-sample settings. If this is violated, the function should still complete but it should also print an appropriate warning message.

The function should return a list containing the members Z (the test statistic), P (the appropriate p value), and CI (the two-sided CI with respect to ‚Äúconf.level‚Äù around p1 in the case of a one-sample test and around p2-p1 in the case of a two-sample test). 

For all test alternatives (‚Äútwo.sided‚Äù, ‚Äúgreater‚Äù, ‚Äúless‚Äù), calculate symmetric CIs based on quantiles of the normal distribution rather than worrying about calculating single-limit confidence bounds.

```{r}
#we are creating a function that can run a z-test for proportions
#must return z value, p value, CI,

options(repos = c(CRAN = "https://cloud.r-project.org")) #I was getting errors while trying to knit and apparently its because I installed a package without mirroring my CRAN

install.packages("crayon") #this package allows for colorful writing, which I want to use for my warning message.
library(crayon)



Z.prop.test <- function(p1, n1, p2 = NULL, n2 = NULL, p0, alternative = "two.sided", conf.level = 0.95){
  
  #Defining null variables which will be used
  zScore <- NULL
  p <- NULL
  se <- NULL
  CIlower <- NULL
  CIupper <- NULL
  CI <- NULL
  results <- NULL
  pStar <- NULL #this is only for two sided tests
  
  if (alternative == "two.sided")  #alternative hypothesis: p1 does not equal p2
  {
   
   pStar <- ( (n1*p1) + (n2*p2) )/(n1 + n2) #calulates p*
   se <- sqrt(pStar* (1 - pStar) * ( (1/n1) + (1/n2) ) )
   zScore <- (p2 - p1)/(sqrt( pStar * (1 - pStar) * ((1/n1)+ (1/n2)))) #calculates z score
   p <- 2*pnorm(abs(zScore), lower.tail = F) #calculates p value? I'm not sure I did this right. I think this works. 
   CIlower <- pStar - qnorm(conf.level+((1-conf.level)/2))*se #calculates confidence interval lower bound
   CIupper <- pStar + qnorm(conf.level+((1-conf.level)/2))*se #calculates confidence interval upper bound
   results <- c(zScore, p, CIlower, CIupper)
   names(results) <- c("Z Score", "p-value", "CI lower", "CI upper")
   print(results)
   
   #now checking for assumptions
   if( ((n1*p1) <= 5) | ((n2*p2) <= 5))
    {
      cat(red("Warning: assumption np > 5 is not met."))
   }
   if ( (n1*(1-p1)) <= 5 | (n2*(1-p2)) <= 5)
   {
     cat(red("Warning: assumption n(1-p) > 5 is not met."))
   }
   
  }
  if (alternative == "greater") #alternative hypothesis: p1 is greater than p0
  {
    se <- (sqrt(p0*(1-p0)/n1)) #calculates standard error
    zScore <- (p1-p0)/se # calculates z score
    p <- pnorm(zScore, lower.tail = F) #calculates p value for z score
    CIlower <- p1 - qnorm(conf.level+((1-conf.level)/2))*se
    CIupper <- p1 + qnorm(conf.level+((1-conf.level)/2))*se
    results <- c(zScore, p, CIlower, CIupper)
    names(results) <- c("Z Score", "p-value", "CI lower", "CI upper")
    print(results)
    
   #now checking for assumptions
   if( ((n1*p1) <= 5) )
    {
      cat(red("Warning: assumption np > 5 is not met."))
   }
   if ( (n1*(1-p1)) <= 5 )
   {
     cat(red("Warning: assumption n(1-p) > 5 is not met."))
   }
  }
  if (alternative == "less") #alternative hypothesis: p1 is less than p0
  {
    se <- (sqrt(p0*(1-p0)/n1))
    zScore <- (p1-p0)/se
    p <- pnorm(zScore, lower.tail = T)
    CIlower <- p1 - qnorm(conf.level+((1-conf.level)/2))*se
    CIupper <- p1 + qnorm(conf.level+((1-conf.level)/2))*se
    results <- c(zScore, p, CIlower, CIupper)
    names(results) <- c("Z Score", "p-value", "CI lower", "CI upper")
    print(results)
    
       #now checking for assumptions
   if( ((n1*p1) <= 5) )
    {
      cat(red("Warning: assumption np > 5 is not met."))
   }
   if ( (n1*(1-p1)) <= 5 )
   {
     cat(red("Warning: assumption n(1-p) > 5 is not met."))
   }
  }

}

#test for one tailed upper test
Z.prop.test(p1 = 0.53, n1 = 1000, p0 = 0.50, alternative = "greater", conf.level = 0.95)

#test for one tailed lower test
Z.prop.test(p1 = 0.47, n1 = 1000, p0 = 0.50, alternative = "less", conf.level = 0.95)

#test for two tailed test
Z.prop.test(p1 = 0.50, n1 = 1000, p2 = 0.47, n2 = 1000, alternative = "two.sided", conf.level = 0.95)

```


## Problem 2: Linear Regression: longevity ~ mean brain size (and log transformed)

The dataset from Kamilar and Cooper has in it a large number of variables related to life history and body size. For this exercise, the end aim is to fit a simple linear regression model to predict longevity (MaxLongevity_m) measured in months from species‚Äô brain size (Brain_Size_Species_Mean) measured in grams. 

Do the following for both longevity~brain size and log(longevity)~log(brain size):

Fit the regression model and, using {ggplot2}, produce a scatterplot with the fitted line superimposed upon the data. Append the the fitted model equation to your plot (HINT: use the function geom_text()).

Identify and interpret the point estimate of the slope (ùõΩ1), as well as the outcome of the test associated with the hypotheses. H0: ùõΩ1= 0; HA: ùõΩ1 ‚â† 0. 

Also, find a 90 percent CI for the slope (ùõΩ1) parameter.

Using your model, add lines for the 90 percent confidence and prediction interval bands on the plot and add a legend to differentiate between the lines.

Produce a point estimate and associated 90 percent PI for the longevity of a species whose brain weight is 800 gm. Do you trust the model to predict observations accurately for this value of the explanatory variable? Why or why not?

Looking at your two models, which do you think is better? Why?

### LONGEVITY ~ BRAIN SIZE
```{r}
install.packages("geomtextpath") #I found this cool function in {geomtextpath} for labeling the fit line
library(geomtextpath)
library(ggplot2)

#importing dataset
file <- ("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/refs/heads/master/AN588_Fall23/KamilarAndCooperData.csv")
data <- read.csv(file, sep = ",", header = T)


#running linear model: longevity ~ brain size
lm_longVsBrainSize <- lm(data = data, MaxLongevity_m ~ Brain_Size_Species_Mean) #linear regression 
summary(lm_longVsBrainSize)

#creating a label for the fit line
plotLabel <- paste("y =", as.factor(lm_longVsBrainSize$coefficients[1]), "x +", as.factor(lm_longVsBrainSize$coefficients[2])) 

#creating the scatterplot
plot1 <- ggplot(data = data, mapping =aes(x = Brain_Size_Species_Mean, y = MaxLongevity_m)) +
  geom_point() +
  geom_labelsmooth(method = "lm", label = plotLabel) +
  labs(x = "Mean Species Brain Size", y = "Max Longevity", title = "Mean      Species Brain Size vs. Max Longevity")
print(plot1)

#Identifying and interpreting slope estimate (ùõΩ1)
print("The slope estimate (ùõΩ1) is equal to 1.218. This means that for every 1 unit increase in Mean Species Brain Size, Max Longevity increases by 1.218 years")

#Interpreting outcome of hypothesis test, whether or not ùõΩ1 = 0.
print("There is sufficient evidence to reject H0, that ùõΩ1 = 0, as the p-value is extremely low.")

#Find 90% confidence interval for the slope 
CIlower_slope <- lm_longVsBrainSize$coefficients[2] - qt(0.95, df = 126)*0.1101 
CIupper_slope <- lm_longVsBrainSize$coefficients[2] + qt(0.95, df = 126)*0.1101 
#note: 0.1101 is the standard error for the slope, taken from the lm
CI <- paste(CIlower_slope, CIupper_slope, sep = ", ")
paste("90% Confidence Interval for ùõΩ1: ", CI)

#add lines for 90% confidence interval + prediction interval bands

ci <- predict(lm_longVsBrainSize, newdata = data.frame(Brain_Size_Species_Mean = data$Brain_Size_Species_Mean), interval = "confidence", level = 0.90, na.omit = T) #creating a confidence interval for the mean y value at a given value of x

#combining the data from ci with the brain sizes and longevities from the original data set into a data frame called dfCI
dfCI <- data.frame(cbind(ci, data$Brain_Size_Species_Mean, data$MaxLongevity_m))

  
#now making a 90% prediction interval 
pi <- predict(lm_longVsBrainSize, newdata = data.frame(Brain_Size_Species_Mean = data$Brain_Size_Species_Mean), interval = "prediction", level = 0.90) 
#creating a 90% prediction interval, which is essentially a confidence interval for the value of y given a specific value of x

#combining the prediction interval, confidence interval, and brain size and longevity data into a dataframe called df_PIandCI
df_PIandCI <- data.frame(cbind(ci, data$Brain_Size_Species_Mean, data$MaxLongevity_m, pi))
names(df_PIandCI) <- c("C_fit", "C_lwr", "C_upr", "brainSize", "longevity", "P_fit", "P_lwr", "P_upr")

#making the plot which includes the confidence interval
plot2 <- ggplot(data = df_PIandCI, aes(x = brainSize, y = longevity))+
  geom_point()+
  geom_line(aes(x = brainSize, y = C_fit), color = "black", show.legend = T)+ #fit line
  geom_line(aes(x = brainSize, y = C_lwr), color = "blue", show.legend = T)+ #CI lower 
  geom_line(aes(x = brainSize, y = C_upr), color = "blue", show.legend = T)+ #CI upper
  geom_line(aes(x = brainSize, y = P_lwr), color = "red", show.legend = T)+ #PI lower
  geom_line(aes(x = brainSize, y = P_upr), color = "red", show.legend = T)+ #PI upper
  labs(x = "Mean Species Brain Size", y = "Max Longevity", title = "Max   Longevity vs. Mean Species Brain Size")
  scale_color_manual(values = colors)
plot2

#point estimate for a species brain weight is 800 gm
pointEstimate <- data.frame(predict(lm_longVsBrainSize, newdata = data.frame(Brain_Size_Species_Mean = 800), interval = "prediction", confidence = 0.90))

paste("The point estimate is ", pointEstimate[1], ".", " The 90% confidence interval for this point estimate is ", pointEstimate[2], ",", pointEstimate[3], sep = "")  
```

### LOG(LONGEVITY) ~ LOG(BRAIN SIZE)
```{r}
library(geomtextpath)
library(ggplot2)

#creating log-transformed variables in data set
data$logBrainSize <- log(data$Brain_Size_Species_Mean)
data$logLongevity <- log(data$MaxLongevity_m)

#running linear model: log longevity ~ log brain size
lm_LOGlong_Vs_LOGBrainSize <- lm(data = data, logLongevity ~ logBrainSize) #linear regression 
summary(lm_LOGlong_Vs_LOGBrainSize)

#creating a label for the fit line
plotLabel2 <- paste("y =", as.factor(lm_LOGlong_Vs_LOGBrainSize$coefficients[1]), "x +", as.factor(lm_LOGlong_Vs_LOGBrainSize$coefficients[2])) 

#creating the scatterplot
plot3 <- ggplot(data = data, mapping =aes(x = logBrainSize, y = logLongevity)) +
  geom_point() +
  geom_labelsmooth(method = "lm", label = plotLabel2) +
  labs(x = "Log Mean Species Brain Size", y = "Log Max Longevity", title = "Log Mean Species Brain Size vs. Log Max Longevity")
print(plot3)

#Identifying and interpreting slope estimate (ùõΩ1)
print("The slope estimate (ùõΩ1) is equal to 0.234. This means that for every 1 unit increase in Log Mean Species Brain Size, Log Max Longevity increases by 0.234 years" )

#Interpreting outcome of hypothesis test, whether or not ùõΩ1 = 0.
print("There is sufficient evidence to reject H0, that ùõΩ1 = 0, as the p-value is extremely low.")

#Find 90% confidence interval for the slope 
CIlower_slope2 <- lm_LOGlong_Vs_LOGBrainSize$coefficients[2] - qt(0.95, df = 126)*0.0178 
CIupper_slope2 <- lm_LOGlong_Vs_LOGBrainSize$coefficients[2] + qt(0.95, df = 126)*0.0178 
#note: 0.0178 is the standard error for the slope, taken from the lm
CI <- paste(CIlower_slope2, CIupper_slope2, sep = ", ")
paste("90% Confidence Interval for ùõΩ1: ", CI)

#add lines for 90% confidence interval + prediction interval bands

ci2 <- predict(lm_LOGlong_Vs_LOGBrainSize, newdata = data.frame(logBrainSize = data$logBrainSize), interval = "confidence", level = 0.90) #creating a confidence interval for the mean y value at a given value of x

#combining the data from ci with the brain sizes and longevities from the original data set into a data frame called dfCI
dfCI2 <- data.frame(cbind(ci2, data$logBrainSize, data$logLongevity))

  
#now making a 90% prediction interval 
pi2 <- predict(lm_LOGlong_Vs_LOGBrainSize, newdata = data.frame(logBrainSize = data$logBrainSize), interval = "prediction", level = 0.90) 
#creating a 90% prediction interval, which is essentially a confidence interval for the value of y given a specific value of x

#combining the prediction interval, confidence interval, and brain size and longevity data into a dataframe called df_PIandCI
df_PIandCI_2 <- data.frame(cbind(ci2, data$logBrainSize, data$logLongevity, pi2))
names(df_PIandCI_2) <- c("C_fit2", "C_lwr2", "C_upr2", "logBrainSize", "logLongevity", "P_fit2", "P_lwr2", "P_upr2")

#making the plot which includes the confidence interval
plot4 <- ggplot(data = df_PIandCI_2, aes(x = logBrainSize, y = logLongevity))+
  geom_point()+
  geom_line(aes(x = logBrainSize, y = C_fit2), color = "black", show.legend = T)+ #fit line
  geom_line(aes(x = logBrainSize, y = C_lwr2), color = "blue", show.legend = T)+ #CI lower 
  geom_line(aes(x = logBrainSize, y = C_upr2), color = "blue", show.legend = T)+ #CI upper
  geom_line(aes(x = logBrainSize, y = P_lwr2), color = "red", show.legend = T)+ #PI lower
  geom_line(aes(x = logBrainSize, y = P_upr2), color = "red", show.legend = T)+ #PI upper
  labs(x = "Log Mean Species Brain Size", y = "Log Max Longevity", title = "Log Max Longevity vs. Log Mean Species Brain Size")
  scale_color_manual(values = colors)
plot4

#point estimate for a species brain weight is 800 gm
pointEstimate2 <- data.frame(predict(lm_LOGlong_Vs_LOGBrainSize, newdata = data.frame(logBrainSize = log(800)), interval = "prediction", confidence = 0.90)) #this calculates log max longevity

expPointEstimate2 <- exp(pointEstimate2) #this calculates actual max longevity and associated confidence intervals

paste("The point estimate is ", expPointEstimate2[1], ".", " The 90% confidence interval for this point estimate is ", expPointEstimate2[2], ", ", expPointEstimate2[3], sep = "")  

```

### Which Model is Better?
```{r}
plot1 #non-log
plot3 #log

summary(lm_longVsBrainSize) #non-log
summary(lm_LOGlong_Vs_LOGBrainSize) #log

print("The log-transformed model seems to be a better fit. It visually fits the data better and has a greater R-squared value.")
```



## Challenges
1. It was a little bit difficult for me to keep track of what was going on with the function in the first challenge. There were a lot of variables and a lot of calculation on top of many if statements. 
2. I had trouble using the geom_text() function to label the fit line so I had to find a different function online. 
3. I couldn't figure out how to label the confidence interval and prediction interval lines. I tried using show.legend = T, and scale_color_manual() but couldn't get it work. 
4. I had to remind myself what the difference between confidence and prediction intervals were. I left some comments during that part which I think accurately describes what they are though I'm not 100% confident (haha get it?).
5. I was confused why the predict function did not get the same value for y as when I manually calculated it using the coefficients from the linear model. It was very close but I thought they should be exactly the same considering that the predict() function uses the linear model. 